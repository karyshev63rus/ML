{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"pics/otus.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pandas.tools.plotting import table\n",
    "from sklearn import datasets\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 8]\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Задачи машинного обучения\n",
    "* Обучение с учителем\n",
    "    * Регрессия\n",
    "    * Классификация\n",
    "* Обучение без учителя\n",
    "    * Кластеризация\n",
    "    * Снижение размерности\n",
    "* Обучение с подкреплением"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Обучение с учителем** - есть некоторое количество примеров, для которых известны ответы.\n",
    "* ответы числа - регрессия\n",
    "* ответы классы - классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * x + np.random.randn(100, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[0].scatter(x, y)\n",
    "ax[0].set_title(\"Regression problem \\n What is y value for new x?\")\n",
    "ax[0].set_xlabel(\"x (feature)\")\n",
    "ax[0].set_ylabel(\"y (target)\")\n",
    "\n",
    "x1 = 2 * np.random.rand(100, 1)\n",
    "x2 = 4 + 3 * np.random.randn(100, 1)\n",
    "\n",
    "ax[1].scatter(x1[x1 > 1], x2[x1 > 1], label=\"class 1\", c='r')\n",
    "ax[1].scatter(x1[x1 <= 1], x2[x1 <= 1], label=\"class 2\", c='b')\n",
    "ax[1].set_title(\"Classification problem \\n What is the color for the new (x1, x2) pair?\")\n",
    "ax[1].set_xlabel(\"x1 (feature)\")\n",
    "ax[1].set_ylabel(\"x2 (feature)\")\n",
    "ax[1].legend()\n",
    "fig.savefig(\"pics/supervised.pdf\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# С учителем - классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = datasets.make_classification(n_features=2, n_informative=2, n_redundant=0, n_repeated=0, random_state=1)\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "colors = ['yellow' if y_i else 'blue' for y_i in y]\n",
    "plt.scatter(X[:, 0], X[:, 1], c=colors)\n",
    "plt.title(\"Classification problem \\n What is the color for the new (x1, x2) pair?\")\n",
    "plt.xlabel(\"x1 (feature)\")\n",
    "plt.ylabel(\"x2 (feature)\")\n",
    "plt.savefig('pics/classification.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Построим случайную прямую. Насколько хорошо она описывает данные?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_naive = np.arange(-0.5, 0.5, 0.1)\n",
    "y_naive = 7 * x_naive + 1\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=colors)\n",
    "plt.title(\"Classification problem \\n What is the color for the new (x1, x2) pair?\")\n",
    "plt.xlabel(\"x1 (feature)\")\n",
    "plt.ylabel(\"x2 (feature)\")\n",
    "plt.plot(x_naive, y_naive, c='red', label='descision boundary naive')\n",
    "plt.legend()\n",
    "plt.savefig('pics/classification_random_line.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Как принимается решение\n",
    "\n",
    "Простой вариант - узнать, с какой стороны от гиперплоскости находится точка\n",
    "\n",
    "$$\\hat{y} = sign(x\\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w = np.array([7, -1, 1]) # Ax + By + C = 0\n",
    "     \n",
    "# Замечание: расстояние от точки (x0, y0) до прямой Ax + By + C это abs(Ax0 + By0 + C) / sqrt(A^2 + B^2)\n",
    "    \n",
    "def predict(x, w):\n",
    "    return np.sign(x.dot(w))\n",
    "\n",
    "x_pred = np.hstack([np.random.rand(10, 2) * 4 - 2, np.ones(10).reshape(-1, 1)])\n",
    "y_pred = predict(x_pred, w)\n",
    "\n",
    "print x_pred.shape\n",
    "print y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_naive = np.arange(-0.5, 0.5, 0.1)\n",
    "y_naive = 7 * x_naive + 1\n",
    "\n",
    "plt.scatter(x_pred[:, 0], x_pred[:, 1], c=['yellow' if y_i > 0 else 'green' for y_i in y_pred])\n",
    "plt.title(\"Classification problem \\n What is the color for the new (x1, x2) pair?\")\n",
    "plt.xlabel(\"x1 (feature)\")\n",
    "plt.ylabel(\"x2 (feature)\")\n",
    "plt.plot(x_naive, y_naive, c='red', label='descision boundary naive')\n",
    "plt.legend()\n",
    "plt.savefig('pics/classification_random_line.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Как оценить результат - простой вариант\n",
    "\n",
    "Отступ (margin) - величина $M_i = y_i \\cdot x_i\\theta$ (для $y = 1$ или $y = -1$), где $x_i$ - элемент обучающей выборки, $y_i$ - его класс\n",
    "\n",
    "$$M_i \\leq 0 \\Rightarrow y_i \\neq \\hat{y_i}$$\n",
    "$$M_i > 0 \\Rightarrow y_i = \\hat{y_i}$$\n",
    "\n",
    "Функция потерь zero-one loss:\n",
    "$$ f(x) = \\begin{cases}\n",
    "      1, & \\text{если}\\space \\hat{y} \\neq y, \\\\\n",
    "      0, & \\text{если}\\space \\hat{y} = y\n",
    "    \\end{cases}\n",
    "$$ \n",
    "\n",
    "Эмпирический риск:\n",
    "$$Q(\\theta, x) = \\frac{1}{n} \\sum_{i=1}^{n} f(x) = \\frac{1}{n} \\sum_{i=1}^{n}[M_i < 0]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_pred = np.hstack([X, np.ones(X.shape[0]).reshape(-1, 1)])\n",
    "y_pred = predict(x_pred, w)\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[1].plot(x_naive, y_naive, c='red', label='descision boundary naive')\n",
    "ax[1].scatter(x_pred[:, 0], x_pred[:, 1], c=['green' if pred else 'red' for pred in y_pred == y])\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Classification problem \\n What is the color for the new (x1, x2) pair?\")\n",
    "ax[1].set_xlabel(\"x1 (feature)\")\n",
    "ax[1].set_ylabel(\"x2 (feature)\")\n",
    "\n",
    "ax[0].scatter(X[:, 0], X[:, 1], c=colors)\n",
    "ax[0].plot(x_naive, y_naive, c='red', label='descision boundary naive')\n",
    "ax[0].set_title(\"Classification problem \\n What is the color for the new (x1, x2) pair?\")\n",
    "ax[0].set_xlabel(\"x1 (feature)\")\n",
    "ax[0].set_ylabel(\"x2 (feature)\")\n",
    "ax[0].legend()\n",
    "fig.savefig('pics/classification_error.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xmin, xmax = -4, 4\n",
    "xx = np.linspace(xmin, xmax, 100)\n",
    "lw = 2\n",
    "plt.plot([xmin, 0, 0, xmax], [1, 1, 0, 0], lw=lw, label=\"Zero-one loss\")\n",
    "# plt.plot(xx, np.log2(1 + np.exp(-xx)), color='green', lw=lw, label=\"Log loss\")\n",
    "plt.xlabel(r\"Decision function $f(x)$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"$L(y=1, f(x))$\")\n",
    "plt.ylim((-1, 2))\n",
    "fig.savefig('pics/zero_one_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "print y\n",
    "print y_pred\n",
    "zero_one_loss(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Переформулируем задачу\n",
    "Вместо класса будем предсказывать вероятность принадлежности классу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\\hat{p} = \\sigma(x\\theta) $$\n",
    "\n",
    "где \n",
    "\n",
    "$$\\sigma(t)=\\frac{1}{1 + exp(-t)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t = np.linspace(-10, 10, 100)\n",
    "sig = 1 / (1 + np.exp(-t))\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.plot([-10, 10], [0, 0], \"k-\")\n",
    "plt.plot([-10, 10], [0.5, 0.5], \"k:\")\n",
    "plt.plot([-10, 10], [1, 1], \"k:\")\n",
    "plt.plot([0, 0], [-1.1, 1.1], \"k-\")\n",
    "plt.plot(t, sig, \"b-\", linewidth=2, label=r\"$\\sigma(t) = \\frac{1}{1 + e^{-t}}$\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend(loc=\"upper left\", fontsize=20)\n",
    "plt.axis([-10, 10, -0.1, 1.1])\n",
    "plt.savefig(\"pics/logistic_function_plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Предсказание\n",
    "\n",
    "$$ y = \\begin{cases}\n",
    "      0, & \\text{если}\\space \\hat{p} < 0.5, \\\\\n",
    "      1, & \\text{если}\\space \\hat{p} \\geq 0.5\n",
    "    \\end{cases}\n",
    "$$    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Оценка одного элемента выборки\n",
    "\n",
    "$$ Q(\\theta, x_i) = \\begin{cases}\n",
    "      -log(\\hat{p}), & \\text{если}\\space y = 1, \\\\\n",
    "      -log(1-\\hat{p}), & \\text{если}\\space y=0 \n",
    "    \\end{cases}\n",
    "$$    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Для многих элементов выборки (log loss)\n",
    "\n",
    "$$ Q(\\theta, x) = - \\frac{1}{m}\\sum_{i=1}^{n}[y_i \\log (\\hat{p}_i) + (1-y_i)log(1-\\hat{p}_i)]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xmin, xmax = -4, 4\n",
    "xx = np.linspace(xmin, xmax, 100)\n",
    "lw = 2\n",
    "plt.plot([xmin, 0, 0, xmax], [1, 1, 0, 0], lw=lw, label=\"Zero-one loss\")\n",
    "plt.plot(xx, np.log2(1 + np.exp(-xx)), color='green', lw=lw, label=\"Log loss\")\n",
    "plt.xlabel(r\"Decision function $f(x)$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"$L(y=1, f(x))$\")\n",
    "plt.ylim((-1, 2))\n",
    "plt.savefig(\"pics/logloss.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## В sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(-2, 2, 500).reshape(-1, 1),\n",
    "        np.linspace(-3, 3, 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"g^\")\n",
    "zz = y_proba[:, 1].reshape(x0.shape)\n",
    "contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)\n",
    "left_right = np.array([-3, 3])\n",
    "boundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) / log_reg.coef_[0][1]\n",
    "plt.clabel(contour, inline=1, fontsize=12)\n",
    "plt.plot(left_right, boundary, \"k--\", linewidth=3)\n",
    "plt.xlabel(\"x1 (feature)\")\n",
    "plt.ylabel(\"x2 (feature)\")\n",
    "plt.axis([-3, 3, -2, 2])\n",
    "plt.savefig(\"pics/descision.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Мультиклассовая регрессия\n",
    "\n",
    "Для обучения модели предсказывать $K$ классов можно натренировать $K$ классификаторов 1 против всех (one vs rest) и при предсказании брать максимальное значение. Вероятности нормализуются. Или $K(K-1)/2$ классификаторов one vs one.\n",
    "\n",
    "Рассмотрим другой способ - softmax.\n",
    "\n",
    "Нам необходимо получить значения для $k$ классов - составим матрицу параметров $\\Theta$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$ x = \\begin{bmatrix} 1 & x_{11} & ... & x_{p1} \\\\ 1 & x_{12} & ... & x_{p2} \\\\ ... & ... & ... & ... \\\\ 1 & x_{n1} & ... & x_{n1}\n",
    "\\end{bmatrix} \\quad \n",
    "\\Theta = \\begin{bmatrix} \\theta_{01} &  ... & \\theta_{0k} \\\\ \\theta_{11} & ... & \\theta_{1k} \\\\ ... & ... & ... \\\\ \\theta_{p1} & ... & \\theta_{pk} \\end{bmatrix} \\quad \n",
    "f = \\begin{bmatrix} f_{01} &  ... & f_{0k} \\\\ f_{11} & ... & f_{1k} \\\\ ... & ... & ... \\\\ f_{n1} & ... & f_{nk}\\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Softmax\n",
    "\n",
    "$$ \\hat{p}_k = \\frac{e^{x\\theta_k}}{\\sum_{j=1}^K e^{x\\theta_j}} $$\n",
    "\n",
    "$$ \\hat{y}_k = {argmax}_k \\hat{p}_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Оценка для случая многих классов - cross entropy\n",
    "\n",
    "$$Q(\\Theta, x) = - \\frac{1}{n}\\sum_{i=1}^{n}\\sum_{k=1}^{K} y_{ik} \\log \\hat{p}_{ik}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "print X[:10]\n",
    "print np.unique(Y)\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "logreg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.savefig(\"pics/iris.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Z = logreg.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print Z[:10]\n",
    "print logreg.coef_\n",
    "print logreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Градиентный спуск\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"pics/grad.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Метод градиентного спуска заключается в итеративном и одновременном обновлении значений $\\theta$ в направлении, противоположному градиенту:\n",
    "$$ \\theta := \\theta - \\alpha\\frac{\\partial L}{\\partial \\theta}$$\n",
    "\n",
    "* $\\alpha$ -  скорость спуска\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Посчитаем, чему равен градиент функции потерь $RSS(\\theta)$\n",
    "\n",
    "$$ RSS = \\mathcal{L}(\\theta) = (\\hat{y} - y)^2 $$\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial \\theta_i} = 2(\\hat{y} - y)\\frac{\\partial L}{\\partial \\theta_i}(\\hat{y} - y) = 2(\\hat{y} - y)\\frac{\\partial L}{\\partial \\theta_i}(\\theta_0x_0 + ... + \\theta_1x_1 - y) = 2(\\hat{y} - y)\\cdot x_i$$\n",
    "\n",
    "$$ \\theta_i:= \\theta_i - \\alpha(\\hat{y} - y)\\cdot x_i$$\n",
    "\n",
    "Или:\n",
    "$$ \\frac{\\partial RSS(\\theta)}{\\partial \\theta_i} = 2\\sum_{i=1}^{n}(\\theta^T\\cdot x_i - y_i)x_i$$\n",
    "\n",
    "$$\\nabla_\\theta RSS(\\theta) = \\left( \\begin{matrix} \\frac{\\partial L}{\\partial \\theta_0} \\\\ \\frac{\\partial L}{\\partial \\theta_1} \\\\ ... \\\\ \\frac{\\partial L}{\\partial \\theta_p} \\end{matrix} \\right) = x^\\top(x\\theta - y)$$\n",
    "\n",
    "\n",
    "Для MSE:\n",
    "$$ \\frac{\\partial L}{\\partial \\theta} = \\frac{1}{n} X^\\top(X\\theta - y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * x + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta_best = np.vstack([lin_reg.intercept_, lin_reg.coef_.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]  # add x0 = 1 to each instance\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Псевдокод алгоритма\n",
    "\n",
    "```{python}\n",
    "1.function gd(X, alpha, epsilon):\n",
    "2.    initialise theta \n",
    "3.    do: \n",
    "4.        theta = new_theta\n",
    "5.        new_theta = theta - alpha * grad(X, theta)\n",
    "6.    until dist(new_theta, theta) < epsilon\n",
    "7.    return theta\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), X]\n",
    "\n",
    "alpha = 0.1\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "theta = np.random.randn(2,1)\n",
    "eps = 0.0001\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2. / m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta_old = theta\n",
    "    theta = theta - alpha * gradients\n",
    "    dist = np.linalg.norm(theta - theta_old)\n",
    "    if dist < eps:\n",
    "        break\n",
    "        \n",
    "print iteration, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_gd_examples():\n",
    "    plt.rcParams['axes.labelsize'] = 14\n",
    "    plt.rcParams['xtick.labelsize'] = 12\n",
    "    plt.rcParams['ytick.labelsize'] = 12\n",
    "    theta_path_bgd = []\n",
    "\n",
    "    def plot_gradient_descent(theta, eta, theta_path=None):\n",
    "        m = len(X_b)\n",
    "        plt.plot(X, y, \"b.\")\n",
    "        n_iterations = 1000\n",
    "        for iteration in range(n_iterations):\n",
    "            if iteration < 10:\n",
    "                y_predict = X_new_b.dot(theta)\n",
    "                style = \"b-\" if iteration > 0 else \"r--\"\n",
    "                plt.plot(X_new, y_predict, style)\n",
    "            gradients = 2. / m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "            theta = theta - eta * gradients\n",
    "            if theta_path is not None:\n",
    "                theta_path.append(theta)\n",
    "        plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "        plt.axis([0, 2, 0, 15])\n",
    "        plt.title(r\"$\\eta = {}$\".format(eta), fontsize=16)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    theta = np.random.randn(2,1)  \n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(131); plot_gradient_descent(theta, eta=0.02)\n",
    "    plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "    plt.subplot(132); plot_gradient_descent(theta, eta=0.1, theta_path=theta_path_bgd)\n",
    "    plt.subplot(133); plot_gradient_descent(theta, eta=0.5)\n",
    "    plt.savefig(\"pics/step.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_gd_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib inline\n",
    "fig=plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "t1_surfs = np.arange(0, 8, 1)\n",
    "t2_surfs = np.arange(0, 8, 1)\n",
    "t1_surf, t2_surf = np.meshgrid(t1_surfs, t2_surfs)\n",
    "t = np.c_[np.ravel(t1_surf), np.ravel(t2_surf)]\n",
    "x_b = np.c_[x, np.ones(x.shape[0])]\n",
    "zs = np.array([mean_squared_error(x_b.dot(t_i.reshape(-1, 1)), y) for t_i in t])\n",
    "z = zs.reshape(t1_surf.shape)\n",
    "ax.plot_surface(t2_surf, t1_surf, z, alpha=0.3)\n",
    "\n",
    "ax.scatter(theta[0], theta[1], mean_squared_error(x_b.dot(theta), y) , marker='o')\n",
    "\n",
    "ax.set_title(\"RSS function\")\n",
    "ax.set_xlabel(\"theta0\")\n",
    "ax.set_ylabel(\"theta1 (feature)\")\n",
    "ax.set_zlabel(\"RSS\")\n",
    "plt.savefig('pics/error_function.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Стохастический градиентный спуск\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Проблема - используется вся обучающая выборка на каждом шаге алгоритма  \n",
    "Решение - использовать один случайный элемент выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "```{python}\n",
    "1.function gd(X, alpha, epsilon):\n",
    "2.    initialise theta \n",
    "3.    do: \n",
    "4.        theta = new_theta\n",
    "5.        new_theta = theta - alpha * grad(X, theta)\n",
    "6.    until dist(new_theta, theta) < epsilon\n",
    "7.    return theta\n",
    "```\n",
    "\n",
    "### Стохастический градиентный спуск\n",
    "\n",
    "```{python}\n",
    "1.function sgd(X, alpha, epsilon):\n",
    "2. \tinitialise theta \n",
    "3. \tdo: \n",
    "4.        X = shuffle(X)\n",
    "5.        for x in X:\n",
    "6.            theta = new_theta\n",
    "7.            new_theta = theta - alpha * grad(x, theta)\n",
    "8.\tuntil dist(new_theta, theta) < epsilon\n",
    "9.\treturn theta\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = len(X_b)\n",
    "alpha = 0.01\n",
    "n_epochs = 100\n",
    "t0, t1 = 5., 50  # learning schedule hyperparameters\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    p = np.random.permutation(m)\n",
    "    for idx in p:\n",
    "\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[[idx], :]\n",
    "        yi = y[[idx], :]\n",
    "        \n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        theta = theta - alpha * gradients\n",
    "        \n",
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta_path_sgd = []\n",
    "m = len(X_b)\n",
    "np.random.seed(42)\n",
    "alpha = 0.01\n",
    "n_epochs = 100\n",
    "t0, t1 = 5., 50  # learning schedule hyperparameters\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        if epoch == 0 and i < 20:                    \n",
    "            y_predict = X_new_b.dot(theta)           \n",
    "            style = \"b-\" if i > 0 else \"r--\"         \n",
    "            plt.plot(X_new, y_predict, style)        \n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        theta = theta - alpha * gradients\n",
    "        theta_path_sgd.append(theta)  \n",
    "        \n",
    "    y_predict = X_new_b.dot(theta)   \n",
    "    plt.plot(X_new, y_predict, 'g-')\n",
    "\n",
    "plt.plot(X, y, \"b.\")                                 \n",
    "plt.xlabel(\"$x_1$\", fontsize=18)                     \n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)           \n",
    "plt.axis([0, 2, 0, 15])                              \n",
    "plt.savefig('pics/sgd_plot.pdf')                              \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Упражнение\n",
    "\n",
    "Найти формулы для градиентного спуска для линейной регрессии с регуляризацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Градиентный спуск для логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Бинарная классификация, log loss\n",
    "\n",
    "$$ Q(\\theta, x) = - \\frac{1}{m}\\sum_{i=1}^{n}[y_i \\log (\\hat{p}_i) + (1-y_i)log(1-\\hat{p}_i)]$$\n",
    "\n",
    "$$ \\frac{\\partial Q(\\theta_j, x)}{\\partial \\theta_i} = \\frac{1}{n} \\sum_{i=1}^{n}(\\sigma(\\theta^T\\cdot x_i) - y_i)x_ij$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$Q(\\Theta, x) = - \\frac{1}{n}\\sum_{i=1}^{n}\\sum_{k=1}^{K} y_{ik} \\log \\hat{p}_{ik}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "$$\\nabla_{\\theta_k}  Q(\\Theta, x) = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{p}_{ki} - y_{ki})x_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "print X[:10]\n",
    "print np.unique(Y)\n",
    "\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10)\n",
    "softmax_reg.fit(X, Y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print softmax_reg.coef_\n",
    "print softmax_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print logreg.coef_\n",
    "print logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = softmax_reg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.savefig('pics/irissm.pdf') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Линейно неразделимый случай\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "x, y = datasets.make_circles(n_samples=n_samples, factor=.5, noise=noise)\n",
    "plt.scatter(x[:,0], x[:,1], c=y)\n",
    "plt.savefig('pics/circles.pdf') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X, y, grid_step=.01, poly_featurizer=None):\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_step),\n",
    "    np.arange(y_min, y_max, grid_step))\n",
    "    Z = clf.predict(poly_featurizer.transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    print xx.shape, yy.shape, Z.shape\n",
    "    plt.contour(xx, yy, Z, cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_log_reg(noise, c):\n",
    "    n_samples = 1500\n",
    "    x, y = datasets.make_circles(n_samples=n_samples, factor=.5, noise=noise)\n",
    "    poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_poly = poly_features.fit_transform(x)\n",
    "    logit = LogisticRegression(C=c)\n",
    "    logit.fit(X_poly, y)\n",
    "    plot_boundary(logit, x, y, grid_step=.01, poly_featurizer=poly_features)\n",
    "    plt.scatter(x[:,0], x[:,1], c=y)\n",
    "    plt.savefig('pics/circles{}{}'.format(noise, c).replace('.', '') + '.pdf') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "noise = .05\n",
    "plot_log_reg(noise, 0.001)\n",
    "plot_log_reg(noise, 0.01)\n",
    "plot_log_reg(noise, 0.1)\n",
    "plot_log_reg(noise, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "noise = .20\n",
    "plot_log_reg(noise, 0.001)\n",
    "plot_log_reg(noise, 0.01)\n",
    "plot_log_reg(noise, 0.1)\n",
    "plot_log_reg(noise, 1)\n",
    "plot_log_reg(noise, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
